"""from datetime import datetimefrom typing import Dict, List, Optional, Anyimport asyncioimport jsonimport loggingimport os"""Production ChatGPT API Client with Child Safety FilteringEnterprise-grade OpenAI integration for AI Teddy Bear"""from src.infrastructure.logging_config import get_loggerlogger = get_logger(__name__, component="infrastructure")# Production-only imports - no fallbacks allowedtry:    from openai import AsyncOpenAI    import openaiexcept ImportError as e:    logger.critical(f"CRITICAL ERROR: OpenAI library is required for production use: {e}")    logger.critical("Install required dependencies: pip install openai")    raise ImportError(f"Missing required dependency: openai") from efrom src.infrastructure.config.settings import get_settingsclass ProductionChatGPTClient:    """Production ChatGPT client with comprehensive child safety filtering."""    def __init__(self, api_key: str = None) -> None:        self.settings = get_settings()        self.api_key = api_key or self.settings.OPENAI_API_KEY        if not self.api_key:            raise ValueError("OpenAI API key is required for production use")        self.client = AsyncOpenAI(api_key=self.api_key)        # Child safety configuration        self.child_safety_rules = [            "Always use child-friendly language",            "Avoid scary or violent content",            "Keep responses age-appropriate",            "Encourage learning and creativity",            "Be supportive and positive",            "Don't discuss adult topics",            "Redirect inappropriate questions to safe topics"        ]        # Forbidden content for children        self.forbidden_words = [            "violence", "weapon", "kill", "death", "blood", "scary",            "nightmare", "monster", "ghost", "demon", "hell", "damn",            "adult", "sex", "drug", "alcohol", "cigarette", "smoke"        ]        # Safe topics for children        self.safe_topics = [            "animals", "nature", "friendship", "family", "school",            "books", "games", "art", "music", "sports", "food",            "colors", "shapes", "numbers", "letters", "stories"        ]    async def generate_child_safe_response(self,                                         message: str,                                         child_age: int,                                         child_preferences: Dict[str, Any] = None) -> Dict[str, Any]:        """Generate child-safe response from ChatGPT with comprehensive filtering."""        try:            # Create child-safe system prompt            system_prompt = self._create_child_safe_system_prompt(child_age, child_preferences)            # Analyze message safety            safety_check = self._analyze_message_safety(message)            if not safety_check["safe"]:                return await self._generate_safety_redirect_response(message, child_age)            # Sanitize input message            safe_message = self._sanitize_message(message)            # Call OpenAI API            response = await self.client.chat.completions.create(                model=self.settings.OPENAI_MODEL,                messages=[                    {"role": "system", "content": system_prompt},                    {"role": "user", "content": safe_message}                ],                max_tokens=self.settings.OPENAI_MAX_TOKENS,                temperature=self.settings.OPENAI_TEMPERATURE,                presence_penalty=0.1,                frequency_penalty=0.1            )            raw_response = response.choices[0].message.content            # Analyze response safety            response_safety = self._analyze_response_safety(raw_response)            if not response_safety["safe"]:                return await self._generate_fallback_response(message, child_age, child_preferences)            # Enhance response for children            enhanced_response = self._enhance_response_for_children(raw_response, child_age, child_preferences)            return {                "response": enhanced_response,                "emotion": self._detect_emotion(enhanced_response),                "safety_analysis": response_safety,                "age_appropriate": True,                "source": "openai_chatgpt",                "timestamp": datetime.now().isoformat(),                "model_used": self.settings.OPENAI_MODEL            }        except openai.RateLimitError as e:            logger.warning(f"OpenAI rate limit exceeded: {e}")            return await self._generate_fallback_response(message, child_age, child_preferences)        except openai.APIError as e:            logger.error(f"OpenAI API error: {e}")            return await self._generate_fallback_response(message, child_age, child_preferences)        except Exception as e:            logger.error(f"Unexpected error in ChatGPT client: {e}")            return await self._generate_fallback_response(message, child_age, child_preferences)    def _create_child_safe_system_prompt(self, child_age: int, preferences: Dict[str, Any] = None) -> str:        """Create child-safe system prompt based on age and preferences."""        preferences = preferences or {}        interests = preferences.get("interests", ["animals", "stories"])        favorite_character = preferences.get("favorite_character", "friendly teddy bear")        age_guidance = {            3: "Use very simple words and short sentences. Focus on basic concepts.",            4: "Use simple words and short sentences. Include fun sounds and repetition.",            5: "Use simple vocabulary. Include basic learning concepts like colors and numbers.",            6: "Use age-appropriate vocabulary. Include educational content about nature and friendship.",            7: "Use clear, friendly language. Include more detailed explanations about the world.",            8: "Use engaging language. Include problem-solving and creativity encouragement.",            9: "Use varied vocabulary. Include more complex concepts explained simply.",            10: "Use rich vocabulary. Include critical thinking and exploration topics."        }        age_specific = age_guidance.get(child_age, age_guidance[6])        return f"""You are a friendly, caring AI assistant designed specifically for children aged {child_age}.SAFETY RULES (NEVER BREAK THESE):- Always use child-friendly, positive language- Never discuss violence, scary content, or adult topics- Keep all responses age-appropriate for a {child_age}-year-old- If asked about inappropriate topics, redirect to safe subjects- Be encouraging, supportive, and educational- Focus on learning, creativity, and funCHILD PROFILE:- Age: {child_age} years old- Interests: {', '.join(interests)}- Favorite character: {favorite_character}RESPONSE GUIDELINES:- {age_specific}- Include the child's interests when possible- Use the favorite character in examples if appropriate- Keep responses under 150 words- End with a friendly question or encouragement- Be warm, caring, and patientFORBIDDEN TOPICS:- Violence, weapons, fighting, death- Scary content, monsters, nightmares- Adult topics, relationships, mature content- Negative emotions without positive resolution- Dangerous activities or risky behaviorSAFE TOPICS TO FOCUS ON:- Animals, nature, friendship, family- Learning, school, books, art, music- Games, sports, healthy activities- Colors, shapes, numbers, letters- Stories, imagination, creativity"""    async def _generate_fallback_response(self, message: str, child_age: int, preferences: Dict[str, Any] = None) -> Dict[str, Any]:        """Generate safe fallback response when API is unavailable."""        fallback_responses = {            3: "Hello! I'm your friendly teddy bear! Would you like to hear a story about animals?",            4: "Hi there! Let's talk about something fun! Do you like colors? What's your favorite color?",            5: "Hello friend! I love talking with you! Would you like to learn about numbers or letters today?",            6: "Hi! I'm so happy to chat with you! Would you like to hear about nature or animals?",            7: "Hello! It's great to meet you! Would you like to explore something new together?",            8: "Hi there! I enjoy our conversations! What would you like to create or discover today?",            9: "Hello friend! I'm here to learn and explore with you! What interests you most?",            10: "Hi! I love discussing interesting topics with you! What would you like to talk about?"        }        response = fallback_responses.get(child_age, fallback_responses[6])        return {            "response": response,            "emotion": "friendly",            "safety_analysis": {"safe": True, "severity": "none", "issues": []},            "age_appropriate": True,            "source": "fallback_safe",            "timestamp": datetime.now().isoformat()        }    def _analyze_message_safety(self, message: str) -> Dict[str, Any]:        """Analyze safety of incoming message."""        message_lower = message.lower()        issues = []        # Check for forbidden words        for word in self.forbidden_words:            if word in message_lower:                issues.append(f"Contains forbidden word: {word}")        # Check message length        if len(message) > 500:            issues.append("Message too long")        severity = "high" if len(issues) > 2 else "medium" if issues else "none"        return {            "safe": len(issues) == 0,            "severity": severity,            "issues": issues        }    def _analyze_response_safety(self, response: str) -> Dict[str, Any]:        """Analyze safety of AI response."""        response_lower = response.lower()        issues = []        # Check for forbidden words in response        for word in self.forbidden_words:            if word in response_lower:                issues.append(f"Response contains forbidden word: {word}")        return {            "safe": len(issues) == 0,            "severity": "none" if len(issues) == 0 else "medium",            "issues": issues        }    def _sanitize_message(self, message: str) -> str:        """Sanitize message by removing unsafe content."""        sanitized = message        # Remove forbidden words        for word in self.forbidden_words:            sanitized = sanitized.replace(word, "[FILTERED]")        # Limit message length        if len(sanitized) > 200:            sanitized = sanitized[:200] + "..."        return sanitized    def _enhance_response_for_children(self, response: str, child_age: int, preferences: Dict[str, Any] = None) -> str:        """Enhance response to be more engaging for children."""        preferences = preferences or {}        favorite_character = preferences.get("favorite_character", "teddy bear")        # Add favorite character reference        if len(response) < 100 and favorite_character:            response += f" Your friend {favorite_character} thinks so too!"        # Add age-appropriate encouragement        age_encouragements = {            3: " You're so smart!",            4: " Great question!",            5: " Keep learning!",            6: " You're amazing!",            7: " Fantastic thinking!",            8: " I love your curiosity!",            9: " Excellent wondering!",            10: " That's brilliant!"        }        encouragement = age_encouragements.get(child_age, age_encouragements[6])        if not response.endswith(('!', '?', '.')):            response += encouragement        return response    def _detect_emotion(self, response: str) -> str:        """Detect emotion from response content."""        response_lower = response.lower()        if any(word in response_lower for word in ['happy', 'joy', 'fun', 'great', 'wonderful', 'amazing']):            return "happy"        elif any(word in response_lower for word in ['learn', 'discover', 'explore', 'think']):            return "curious"        elif any(word in response_lower for word in ['friend', 'together', 'with you']):            return "friendly"        elif any(word in response_lower for word in ['help', 'support', 'care']):            return "caring"        else:            return "neutral"    async def _generate_safety_redirect_response(self, message: str, child_age: int) -> Dict[str, Any]:        """Generate safety redirect response for inappropriate content."""        redirect_responses = {            3: "Let's talk about something nice instead! Do you like puppies?",            4: "How about we talk about your favorite toys?",            5: "Let's learn something fun! What's your favorite animal?",            6: "That's not something we should talk about. Would you like to hear a story instead?",            7: "Let's focus on positive things! What makes you happy?",            8: "How about we explore something interesting and safe?",            9: "Let's discuss something educational and fun!",            10: "That topic isn't appropriate for us. What are you curious about instead?"        }        response = redirect_responses.get(child_age, redirect_responses[6])        return {            "response": response,            "emotion": "redirecting",            "safety_analysis": {"safe": True, "severity": "handled", "issues": ["Redirected unsafe topic"]},            "age_appropriate": True,            "source": "safety_redirect",            "timestamp": datetime.now().isoformat()        }# Factory function for dependency injectiondef create_production_chatgpt_client(api_key: str = None) -> ProductionChatGPTClient:    """Create production ChatGPT client instance."""    return ProductionChatGPTClient(api_key=api_key)