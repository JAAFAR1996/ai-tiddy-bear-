"""from dataclasses import dataclass, fieldfrom datetime import datetime, timedeltafrom typing import Dict, Any, Optional, List, AsyncGeneratorimport asyncioimport jsonimport loggingimport timefrom contextlib import asynccontextmanagerimport psutil"""Production Performance Monitoring ServiceEnterprise-grade metrics collection and performance tracking"""from src.infrastructure.logging_config import get_loggerlogger = get_logger(__name__, component="monitoring")# Production-only imports - no fallbacks allowedtry:    from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry, REGISTRY    from prometheus_client.exposition import MetricsHandler    import redis.asyncio as redisexcept ImportError as e:    logger.critical(f"CRITICAL ERROR: Monitoring dependencies required: {e}")    logger.critical("Install required dependencies: pip install prometheus-client redis")    raise ImportError(f"Missing required monitoring dependencies: {e}") from e@dataclassclass PerformanceMetrics:    """Performance metrics data structure."""    request_count: int = 0    avg_response_time: float = 0.0    error_count: int = 0    memory_usage_mb: float = 0.0    cpu_usage_percent: float = 0.0    active_connections: int = 0    cache_hit_rate: float = 0.0    timestamp: datetime = field(default_factory=datetime.now)class PrometheusMetrics:    """Prometheus metrics definitions."""    def __init__(self) -> None:        self.registry = CollectorRegistry()        # Request metrics        self.request_count = Counter(            'ai_teddy_requests_total',            'Total number of requests',            ['method', 'endpoint', 'status_code'],            registry=self.registry        )        self.request_duration = Histogram(            'ai_teddy_request_duration_seconds',            'Request duration in seconds',            ['method', 'endpoint'],            registry=self.registry        )        # AI metrics        self.ai_response_time = Histogram(            'ai_teddy_ai_response_duration_seconds',            'AI response generation time in seconds',            ['model', 'child_age_group'],            registry=self.registry        )        self.content_safety_checks = Counter(            'ai_teddy_safety_checks_total',            'Total number of content safety checks',            ['result'],            registry=self.registry        )        # Database metrics        self.db_query_duration = Histogram(            'ai_teddy_db_query_duration_seconds',            'Database query duration in seconds',            ['operation', 'table'],            registry=self.registry        )        self.db_connection_pool = Gauge(            'ai_teddy_db_connections_active',            'Active database connections',            registry=self.registry        )        # Cache metrics        self.cache_operations = Counter(            'ai_teddy_cache_operations_total',            'Total cache operations',            ['operation', 'result'],            registry=self.registry        )        # System metrics        self.memory_usage = Gauge(            'ai_teddy_memory_usage_bytes',            'Memory usage in bytes',            registry=self.registry        )        self.cpu_usage = Gauge(            'ai_teddy_cpu_usage_percent',            'CPU usage percentage',            registry=self.registry        )        # Child safety metrics        self.coppa_violations = Counter(            'ai_teddy_coppa_violations_total',            'COPPA compliance violations detected',            ['violation_type'],            registry=self.registry        )        self.safety_alerts = Counter(            'ai_teddy_safety_alerts_total',            'Safety alerts sent to parents',            ['alert_type', 'severity'],            registry=self.registry        )class PerformanceMonitor:    """Production performance monitoring and metrics collection."""    def __init__(self, redis_url: str, enable_prometheus: bool = True) -> None:        self.redis_url = redis_url        self.enable_prometheus = enable_prometheus        self.metrics_cache: Dict[str, Any] = {}        self.redis_client: Optional[redis.Redis] = None        if self.enable_prometheus:            self.prometheus = PrometheusMetrics()        # System monitoring        self.start_time = datetime.now()        self.request_times: List[float] = []        self.max_request_history = 1000    async def initialize(self) -> None:        """Initialize monitoring connections."""        try:            self.redis_client = redis.from_url(self.redis_url, decode_responses=True)            await self.redis_client.ping()            logger.info("Performance monitoring initialized successfully")        except redis.ConnectionError as e:            logger.error(f"Redis connection failed for performance monitoring: {e}")            self.redis_client = None        except redis.TimeoutError as e:            logger.error(f"Redis timeout during initialization: {e}")            self.redis_client = None        except Exception as e:            logger.error(f"Unexpected error initializing performance monitoring - {type(e).__name__}: {e}")            self.redis_client = None    async def close(self) -> None:        """Close monitoring connections."""        if self.redis_client:            await self.redis_client.close()    @asynccontextmanager    async def track_request(self, method: str, endpoint: str) -> AsyncGenerator[None, None]:        """Context manager to track request performance."""        start_time = time.time()        try:            yield            # Request successful            duration = time.time() - start_time            await self.record_request_success(method, endpoint, duration)        except Exception as e:            # Request failed            duration = time.time() - start_time            await self.record_request_error(method, endpoint, duration, str(e))            raise    async def record_request_success(self, method: str, endpoint: str, duration: float) -> None:        """Record successful request metrics."""        try:            if self.enable_prometheus:                self.prometheus.request_count.labels(                    method=method, endpoint=endpoint, status_code="200"                ).inc()                self.prometheus.request_duration.labels(                    method=method, endpoint=endpoint                ).observe(duration)            # Cache recent request times            self.request_times.append(duration)            if len(self.request_times) > self.max_request_history:                self.request_times.pop(0)            # Store in Redis for aggregation            if self.redis_client:                key = f"metrics:requests:{datetime.now().strftime('%Y-%m-%d:%H')}"                await self.redis_client.hincrby(key, "count", 1)                await self.redis_client.hincrbyfloat(key, "total_duration", duration)                await self.redis_client.expire(key, 86400)  # 24 hours        except Exception as e:            logger.error(f"Error recording request success metrics: {e}")    async def record_request_error(self, method: str, endpoint: str, duration: float, error: str) -> None:        """Record failed request metrics."""        try:            if self.enable_prometheus:                self.prometheus.request_count.labels(                    method=method, endpoint=endpoint, status_code="500"                ).inc()            # Store error in Redis            if self.redis_client:                key = f"metrics:errors:{datetime.now().strftime('%Y-%m-%d:%H')}"                await self.redis_client.hincrby(key, "count", 1)                await self.redis_client.lpush(f"errors:recent", json.dumps({                    "timestamp": datetime.now().isoformat(),                    "method": method,                    "endpoint": endpoint,                    "duration": duration,                    "error": error                }))                await self.redis_client.ltrim(f"errors:recent", 0, 100)  # Keep last 100 errors        except Exception as e:            logger.error(f"Error recording request error metrics: {e}")    async def record_ai_response_time(self, model: str, age_group: str, duration: float) -> None:        """Record AI response generation metrics."""        try:            if self.enable_prometheus:                self.prometheus.ai_response_time.labels(                    model=model, child_age_group=age_group                ).observe(duration)        except Exception as e:            logger.error(f"Error recording AI metrics: {e}")    async def record_safety_check(self, result: str) -> None:        """Record content safety check metrics."""        try:            if self.enable_prometheus:                self.prometheus.content_safety_checks.labels(result=result).inc()        except Exception as e:            logger.error(f"Error recording safety metrics: {e}")    async def record_coppa_violation(self, violation_type: str) -> None:        """Record COPPA compliance violation."""        try:            if self.enable_prometheus:                self.prometheus.coppa_violations.labels(violation_type=violation_type).inc()            # Critical alert - log immediately            logger.critical(f"COPPA VIOLATION DETECTED: {violation_type}")        except Exception as e:            logger.error(f"Error recording COPPA violation: {e}")    async def record_safety_alert(self, alert_type: str, severity: str) -> None:        """Record safety alert sent to parents."""        try:            if self.enable_prometheus:                self.prometheus.safety_alerts.labels(                    alert_type=alert_type, severity=severity                ).inc()        except Exception as e:            logger.error(f"Error recording safety alert: {e}")    @asynccontextmanager    async def track_db_query(self, operation: str, table: str):        """Track database query performance."""        start_time = time.time()        try:            yield            duration = time.time() - start_time            if self.enable_prometheus:                self.prometheus.db_query_duration.labels(                    operation=operation, table=table                ).observe(duration)        except (ConnectionError, TimeoutError) as conn_error:            logger.error(f"Database connection error during {operation} on {table}: {conn_error}")            raise        except (ValueError, TypeError) as data_error:            logger.error(f"Data validation error during {operation} on {table}: {data_error}")            raise        except Exception as unexpected_error:            logger.error(f"Unexpected error during {operation} on {table}: {unexpected_error}")            raise    async def update_system_metrics(self) -> None:        """Update system-level metrics."""        try:            # Memory usage            process = psutil.Process()            memory_bytes = process.memory_info().rss            # CPU usage            cpu_percent = process.cpu_percent()            if self.enable_prometheus:                self.prometheus.memory_usage.set(memory_bytes)                self.prometheus.cpu_usage.set(cpu_percent)            # Store in Redis for historical tracking            if self.redis_client:                timestamp = datetime.now().strftime('%Y-%m-%d:%H:%M')                await self.redis_client.hset(f"metrics:system:{timestamp}", mapping={                    "memory_bytes": memory_bytes,                    "cpu_percent": cpu_percent,                    "uptime_seconds": (datetime.now() - self.start_time).total_seconds()                })        except Exception as e:            logger.error(f"Error updating system metrics: {e}")    async def get_performance_summary(self) -> PerformanceMetrics:        """Get current performance summary."""        try:            # Calculate average response time            avg_response_time = (                sum(self.request_times) / len(self.request_times)                if self.request_times else 0.0            )            # Get system metrics            process = psutil.Process()            memory_mb = process.memory_info().rss / 1024 / 1024            cpu_percent = process.cpu_percent()            # Get metrics from Redis if available            request_count = 0            error_count = 0            if self.redis_client:                try:                    hour_key = f"metrics:requests:{datetime.now().strftime('%Y-%m-%d:%H')}"                    request_count = int(await self.redis_client.hget(hour_key, "count") or 0)                    error_key = f"metrics:errors:{datetime.now().strftime('%Y-%m-%d:%H')}"                    error_count = int(await self.redis_client.hget(error_key, "count") or 0)                except (ConnectionError, TimeoutError) as redis_error:                    logger.warning(f"Redis connection error while fetching metrics: {redis_error}")                    # Continue with default values (already set above)                except (ValueError, TypeError) as data_error:                    logger.warning(f"Data parsing error in Redis metrics: {data_error}")                    # Continue with default values                except Exception as unexpected_error:                    logger.warning(f"Unexpected error fetching Redis metrics: {unexpected_error}")                    # Continue with default values            return PerformanceMetrics(                request_count=request_count,                avg_response_time=avg_response_time,                error_count=error_count,                memory_usage_mb=memory_mb,                cpu_usage_percent=cpu_percent,                active_connections=0,  # Would be populated by connection pool                cache_hit_rate=0.0,    # Would be calculated from cache metrics            )        except Exception as e:            logger.error(f"Error getting performance summary: {e}")            return PerformanceMetrics()    async def get_health_status(self) -> Dict[str, Any]:        """Get comprehensive health status."""        try:            metrics = await self.get_performance_summary()            # Determine health status            health_checks = {                "memory": metrics.memory_usage_mb < 1000,  # < 1GB                "cpu": metrics.cpu_usage_percent < 80,    # < 80%                "response_time": metrics.avg_response_time < 2.0,  # < 2s                "error_rate": (metrics.error_count / max(metrics.request_count, 1)) < 0.1  # < 10%            }            overall_healthy = all(health_checks.values())            return {                "healthy": overall_healthy,                "checks": health_checks,                "metrics": {                    "uptime_seconds": (datetime.now() - self.start_time).total_seconds(),                    "memory_usage_mb": metrics.memory_usage_mb,                    "cpu_usage_percent": metrics.cpu_usage_percent,                    "avg_response_time": metrics.avg_response_time,                    "request_count": metrics.request_count,                    "error_count": metrics.error_count,                },                "timestamp": datetime.now().isoformat()            }        except Exception as e:            logger.error(f"Error getting health status: {e}")            return {                "healthy": False,                "error": str(e),                "timestamp": datetime.now().isoformat()            }# Global monitor instance_monitor: Optional[PerformanceMonitor] = Nonedef get_performance_monitor() -> Optional[PerformanceMonitor]:    """Get the global performance monitor instance."""    return _monitordef init_performance_monitor(redis_url: str, enable_prometheus: bool = True) -> PerformanceMonitor:    """Initialize the global performance monitor."""    global _monitor    _monitor = PerformanceMonitor(redis_url, enable_prometheus)    return _monitorasync def start_performance_monitoring() -> None:    """Start performance monitoring background task."""    if _monitor:        await _monitor.initialize()        # Start background system metrics update        async def update_system_metrics_task():            while True:                try:                    await _monitor.update_system_metrics()                    await asyncio.sleep(30)  # Update every 30 seconds                except Exception as e:                    logger.error(f"Error in system metrics update task: {e}")                    await asyncio.sleep(60)  # Retry after 1 minute        asyncio.create_task(update_system_metrics_task())async def stop_performance_monitoring() -> None:    """Stop performance monitoring."""    if _monitor:        await _monitor.close()