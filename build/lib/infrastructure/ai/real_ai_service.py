"""Production Real AI Service for AI Teddy BearEnterprise-grade AI service with OpenAI GPT-4 integration and comprehensive safety filtering.Refactored to be under 300 lines by extracting components"""import loggingimport timeimport hashlibimport jsonfrom typing import Any, Dict, List, Optionalfrom src.infrastructure.logging_config import get_loggerlogger = get_logger(__name__, component="ai")# Production-only imports - no fallbacks allowedtry:    import redis.asyncio as redis    from openai import AsyncOpenAIexcept ImportError as e:    logger.critical(f"CRITICAL ERROR: Required dependencies missing: {e}")    logger.critical("Install required dependencies: pip install openai pydantic redis")    raise ImportError(f"Missing required AI dependencies") from efrom src.infrastructure.config.settings import Settings, get_settingsfrom fastapi import Dependsclass ProductionAIService:    """    Production-grade AI service with real OpenAI GPT-4 integration.    Features:    - Real OpenAI GPT-4 API integration    - Multi-layer content safety filtering    - Age-appropriate response generation    - COPPA compliance (children 13 and under)    - Redis caching for performance    - Comprehensive error handling    - Performance monitoring    """    def __init__(self, settings: Settings = Depends(get_settings)) -> None:        self.settings = settings        openai_api_key = self.settings.ai.OPENAI_API_KEY        if not openai_api_key:            raise ValueError("OpenAI API key is required for production use")        self.client = AsyncOpenAI(api_key=openai_api_key)        self.redis_cache = redis.from_url(            self.settings.redis.REDIS_URL, decode_responses=True        )        # Initialize components        self.safety_analyzer = SafetyAnalyzer(self.client)        self.prompt_builder = PromptBuilder()        # AI model configuration        self.model = "gpt-4-turbo-preview"        self.max_tokens = 200        self.temperature = 0.7        logger.info("Production AI Service initialized with OpenAI GPT-4")    async def generate_child_safe_response(        self,        message: str,        age: int,        context: Optional[ConversationContext] = None,        session_id: Optional[str] = None,    ) -> AIResponse:        """Generate a child-safe AI response using OpenAI GPT-4."""        start_time = time.time()        # Validate age (COPPA compliance)        if age > 13:            logger.warning(                f"Age {age} exceeds COPPA limit (13). Using age 13 for safety."            )            age = 13        # Check cache first        if self.redis_cache and session_id:            cached_response = await self._get_cached_response(message, age, session_id)            if cached_response:                cached_response.cached = True                return cached_response        # Safety check on input        input_safety = await self.safety_analyzer.analyze_safety(message)        if not input_safety["safe"]:            return self._create_safety_redirect_response(                input_safety, time.time() - start_time            )        # Build child-safe prompt        prompt = self.prompt_builder.build_child_safe_prompt(            message, age, context.model_dump() if context else {}        )        try:            # Call OpenAI API            response = await self.client.chat.completions.create(                model=self.model,                messages=[                    {"role": "system", "content": prompt},                    {"role": "user", "content": message},                ],                max_tokens=self.max_tokens,                temperature=self.temperature,                presence_penalty=0.1,                frequency_penalty=0.1,            )            content = response.choices[0].message.content            # Safety check on output            output_safety = await self.safety_analyzer.analyze_safety(content)            if not output_safety["safe"]:                content = self._get_safe_fallback_response(age)                output_safety["safety_score"] = 1.0            # Analyze response characteristics            sentiment = self._analyze_sentiment(content)            topics = self._extract_topics(content)            emotion = self._determine_emotion(content, sentiment)            ai_response = AIResponse(                content=content,                safety_score=output_safety["safety_score"],                age_appropriate=True,                sentiment=sentiment,                topics=topics,                processing_time=time.time() - start_time,                cached=False,                moderation_flags=output_safety.get("flagged_categories", []),                response_type="conversational",                emotion=emotion,            )            # Cache the response            if self.redis_cache and session_id:                await self._cache_response(message, age, session_id, ai_response)            return ai_response        except Exception as e:            logger.error(f"AI generation failed: {e}")            return self._create_error_response(str(e), time.time() - start_time)    def _create_safety_redirect_response(        self, safety_result: Dict, processing_time: float    ) -> AIResponse:        """Create a safe redirect response when input is unsafe"""        safe_responses = [            "Let's talk about something fun and positive! What's your favorite animal?",            "How about we play a word game or tell a story instead?",            "I love talking about happy things! What makes you smile?",            "Let's explore something amazing! Have you ever wondered how rainbows are made?",        ]        import random        content = random.choice(safe_responses)        return AIResponse(            content=content,            safety_score=1.0,            age_appropriate=True,            sentiment="positive",            topics=["redirection", "safety"],            processing_time=processing_time,            cached=False,            moderation_flags=safety_result.get("found_keywords", []),            response_type="safety_redirect",            emotion="caring",        )    def _get_safe_fallback_response(self, age: int) -> str:        """Get a safe fallback response when generated content is unsafe"""        fallbacks = [            f"That's an interesting question! As a friendly teddy bear, I love talking about fun things that are perfect for {age}-year-olds like you!",            "Let me tell you something really cool instead! Did you know that teddy bears love to help children learn and have fun?",            "I have a better idea! Let's talk about your favorite games or stories!",        ]        import random        return random.choice(fallbacks)    def _analyze_sentiment(self, text: str) -> str:        """Analyze sentiment of the text"""        positive_words = [            "happy",            "fun",            "great",            "love",            "awesome",            "wonderful",            "exciting",        ]        negative_words = ["sad", "bad", "wrong", "sorry", "unfortunately"]        text_lower = text.lower()        positive_count = sum(1 for word in positive_words if word in text_lower)        negative_count = sum(1 for word in negative_words if word in text_lower)        if positive_count > negative_count:            return "positive"        elif negative_count > positive_count:            return "negative"        else:            return "neutral"    def _extract_topics(self, text: str) -> List[str]:        """Extract main topics from the text"""        # Simple topic extraction - in production, use NLP        topic_keywords = {            "learning": ["learn", "know", "understand", "teach"],            "play": ["play", "game", "fun", "toy"],            "story": ["story", "tale", "once upon", "adventure"],            "animals": ["animal", "pet", "dog", "cat", "bear"],            "science": ["science", "how", "why", "work"],            "friendship": ["friend", "together", "help", "share"],        }        found_topics = []        text_lower = text.lower()        for topic, keywords in topic_keywords.items():            if any(keyword in text_lower for keyword in keywords):                found_topics.append(topic)        return found_topics if found_topics else ["general"]    def _determine_emotion(self, content: str, sentiment: str) -> str:        """Determine the emotional tone of the response"""        if sentiment == "positive":            if "!" in content:                return "excited"            elif "?" in content:                return "curious"            else:                return "happy"        elif sentiment == "negative":            return "empathetic"        else:            return "friendly"    async def _get_cached_response(        self, message: str, age: int, session_id: str    ) -> Optional[AIResponse]:        """Get cached response if available"""        if not self.redis_cache:            return None        try:            cache_key = self._generate_cache_key(message, age, session_id)            cached_data = await self.redis_cache.get(cache_key)            if cached_data:                data = json.loads(cached_data)                return AIResponse(**data)        except Exception as e:            logger.error(f"Cache retrieval failed: {e}")        return None    async def _cache_response(        self, message: str, age: int, session_id: str, response: AIResponse    ) -> None:        """Cache the response for future use"""        if not self.redis_cache:            return        try:            cache_key = self._generate_cache_key(message, age, session_id)            cache_data = response.model_dump_json()            # Cache for 1 hour            await self.redis_cache.setex(cache_key, 3600, cache_data)        except Exception as e:            logger.error(f"Cache storage failed: {e}")    def _generate_cache_key(self, message: str, age: int, session_id: str) -> str:        """Generate a unique cache key"""        key_data = f"{message}:{age}:{session_id}"        return f"ai_response:{hashlib.sha256(key_data.encode()).hexdigest()[:16]}"    def _create_error_response(self, error: str, processing_time: float) -> AIResponse:        """Create a child-friendly error response"""        return AIResponse(            content="Oh! Something went wrong, but don't worry! Let's try talking about something else. What would you like to know?",            safety_score=1.0,            age_appropriate=True,            sentiment="supportive",            topics=["error_recovery"],            processing_time=processing_time,            cached=False,            moderation_flags=[],            response_type="error",            emotion="reassuring",        )