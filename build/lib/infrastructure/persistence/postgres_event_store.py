"""PostgreSQL Event Store Implementation for Event Sourcing."""from datetime import datetimefrom typing import List, Any, Dict, Optionalfrom uuid import UUID, uuid4import jsonimport loggingfrom sqlalchemy import Column, String, Integer, DateTime, Text, Index, selectfrom sqlalchemy.dialects.postgresql import UUID as PGUUID, JSONBfrom sqlalchemy.ext.asyncio import AsyncSessionfrom sqlalchemy.orm import declarative_basefrom src.domain.repositories.event_store import EventStorefrom src.infrastructure.persistence.database import Database"""PostgreSQL Event Store Implementation for Event Sourcing."""from src.infrastructure.logging_config import get_loggerlogger = get_logger(__name__, component="persistence")Base = declarative_base()class EventModel(Base):    """SQLAlchemy model for storing domain events."""    __tablename__ = "domain_events"    # Primary key    event_id: str = Column(PGUUID(as_uuid=True), primary_key=True, default=uuid4)    # Event metadata    aggregate_id: str = Column(PGUUID(as_uuid=True), nullable=False, index=True)    aggregate_type: str = Column(String(100), nullable=False, index=True)    event_type: str = Column(String(100), nullable=False, index=True)    event_version: int = Column(Integer, nullable=False, default=1)    # Event sequence for ordering    sequence_number: int = Column(Integer, nullable=False)    # Event data    event_data: Dict[str, Any] = Column(JSONB, nullable=False)    event_metadata: Optional[Dict[str, Any]] = Column(JSONB, nullable=True)    # Timestamps    created_at: datetime = Column(DateTime, nullable=False, default=datetime.utcnow)    # Indexes for performance    __table_args__ = (        Index("idx_aggregate_sequence", "aggregate_id", "sequence_number"),        Index("idx_event_type_created", "event_type", "created_at"),        Index("idx_aggregate_type", "aggregate_type", "aggregate_id"),    )class PostgresEventStore(EventStore):    """PostgreSQL implementation of EventStore for production use."""    def __init__(self, database: Database) -> None:        """Initialize PostgreSQL event store.        Args:            database: Database instance for connection management        """        self.database = database        self._sequence_cache: Dict[UUID, int] = {}    async def save_events(self, aggregate_id: UUID, events: List[Any]) -> None:        """Save events to PostgreSQL with ACID guarantees.        Args:            aggregate_id: UUID of the aggregate            events: List of domain events to persist        """        if not events:            return        async with self.database.get_session() as session:            try:                # Get current sequence number for this aggregate                current_sequence = await self._get_latest_sequence_number(                    session, aggregate_id                )                # Convert and save each event                for event in events:                    current_sequence += 1                    event_model = EventModel(                        aggregate_id=aggregate_id,                        aggregate_type=event.__class__.__module__.split(".")[-2],                        event_type=event.__class__.__name__,                        event_version=getattr(event, "__version__", 1),                        sequence_number=current_sequence,                        event_data=self._serialize_event(event),                        event_metadata={                            "user_id": getattr(event, "user_id", None),                            "correlation_id": getattr(                                event, "correlation_id", str(uuid4())                            ),                            "causation_id": getattr(                                event, "causation_id", str(uuid4())                            ),                        },                    )                    session.add(event_model)                await session.commit()                # Update cache                self._sequence_cache[aggregate_id] = current_sequence                logger.info(f"Saved {len(events)} events for aggregate {aggregate_id}")            except Exception as e:                await session.rollback()                logger.error(f"Failed to save events for aggregate {aggregate_id}: {e}")                raise    async def load_events(self, aggregate_id: UUID) -> List[Any]:        """Load all events for an aggregate from PostgreSQL.        Args:            aggregate_id: UUID of the aggregate        Returns:            List of domain events in chronological order        """        async with self.database.get_session() as session:            try:                # Query events ordered by sequence number                result = await session.execute(                    select(EventModel)                    .where(EventModel.aggregate_id == aggregate_id)                    .order_by(EventModel.sequence_number)                )                event_models = result.scalars().all()                # Deserialize events                events = []                for model in event_models:                    event = self._deserialize_event(                        model.event_type, model.event_data, model.event_metadata                    )                    if event:                        events.append(event)                logger.debug(                    f"Loaded {len(events)} events for aggregate {aggregate_id}"                )                return events            except Exception as e:                logger.error(f"Failed to load events for aggregate {aggregate_id}: {e}")                raise    async def load_events_after_sequence(        self, aggregate_id: UUID, sequence_number: int    ) -> List[Any]:        """Load events after a specific sequence number.        Args:            aggregate_id: UUID of the aggregate            sequence_number: Load events after this sequence        Returns:            List of domain events after the given sequence        """        async with self.database.get_session() as session:            result = await session.execute(                select(EventModel)                .where(                    EventModel.aggregate_id == aggregate_id,                    EventModel.sequence_number > sequence_number,                )                .order_by(EventModel.sequence_number)            )            event_models = result.scalars().all()            events = []            for model in event_models:                event = self._deserialize_event(                    model.event_type, model.event_data, model.event_metadata                )                if event:                    events.append(event)            return events    async def get_all_aggregate_ids(self, aggregate_type: str) -> List[UUID]:        """Get all aggregate IDs of a specific type.        Args:            aggregate_type: Type name of the aggregate        Returns:            List of aggregate UUIDs        """        async with self.database.get_session() as session:            result = await session.execute(                select(EventModel.aggregate_id)                .where(EventModel.aggregate_type == aggregate_type)                .distinct()            )            return [row[0] for row in result.all()]    async def _get_latest_sequence_number(        self, session: AsyncSession, aggregate_id: UUID    ) -> int:        """Get the latest sequence number for an aggregate.        Args:            session: Database session            aggregate_id: UUID of the aggregate        Returns:            Latest sequence number or 0 if no events exist        """        # Check cache first        if aggregate_id in self._sequence_cache:            return self._sequence_cache[aggregate_id]        # Query database        result = await session.execute(            select(EventModel.sequence_number)            .where(EventModel.aggregate_id == aggregate_id)            .order_by(EventModel.sequence_number.desc())            .limit(1)        )        row = result.scalar_one_or_none()        sequence = row if row is not None else 0        # Update cache        self._sequence_cache[aggregate_id] = sequence        return sequence    def _serialize_event(self, event: Any) -> Dict[str, Any]:        """Serialize domain event to JSON-compatible dictionary.        Args:            event: Domain event instance        Returns:            Serialized event data        """        # Get all attributes that don't start with underscore        event_data = {}        for attr in dir(event):            if not attr.startswith("_") and not callable(getattr(event, attr)):                value = getattr(event, attr)                # Handle special types                if isinstance(value, UUID):                    value = str(value)                elif isinstance(value, datetime):                    value = value.isoformat()                elif hasattr(value, "__dict__"):                    # Handle nested objects                    value = value.__dict__                event_data[attr] = value        return event_data    def _deserialize_event(        self,        event_type: str,        event_data: Dict[str, Any],        event_metadata: Optional[Dict[str, Any]],    ) -> Optional[Any]:        """Deserialize event data back to domain event.        Args:            event_type: Name of the event class            event_data: Serialized event data            event_metadata: Event metadata        Returns:            Domain event instance or None if deserialization fails        """        # Import event classes dynamically        # This is a simplified version - in production, use a proper event registry        try:            if event_type == "ChildRegistered":                from src.domain.events.child_registered import ChildRegistered                return ChildRegistered(**event_data)            elif event_type == "ChildProfileUpdated":                from src.domain.events.child_profile_updated import ChildProfileUpdated                return ChildProfileUpdated(**event_data)            else:                logger.warning(f"Unknown event type: {event_type}")                return None        except Exception as e:            logger.error(f"Failed to deserialize event {event_type}: {e}")            return None    async def create_tables(self) -> None:        """Create event store tables if they don't exist."""        async with self.database.engine.begin() as conn:            await conn.run_sync(Base.metadata.create_all)