import asyncioimport loggingfrom typing import Any, Callable, Dict, Listfrom src.infrastructure.logging_config import get_loggerlogger = get_logger(__name__, component="performance")class BatchLoader:    """    Utility class to batch load related data and prevent N+1 queries.    """    def __init__(self, loader_func: Callable, batch_size: int = 50):        self.loader_func = loader_func        self.batch_size = batch_size        self._pending: Dict[str, List[Any]] = {}        self._results: Dict[str, Any] = {}    async def load(self, key: Any) -> Any:        """Load a single item, batching with other requests."""        batch_key = self._get_batch_key()        if batch_key not in self._pending:            self._pending[batch_key] = []        self._pending[batch_key].append(key)        # If batch is full or after small delay, execute batch        if len(self._pending[batch_key]) >= self.batch_size:            await self._execute_batch(batch_key)        else:            # Small delay to allow batching            await asyncio.sleep(0.001)            if batch_key in self._pending and self._pending[batch_key]:                await self._execute_batch(batch_key)        return self._results.get(key)    async def load_many(self, keys: List[Any]) -> Dict[Any, Any]:        """Load multiple items efficiently."""        results = {}        # Split into batches        for i in range(0, len(keys), self.batch_size):            batch_keys = keys[i : i + self.batch_size]            batch_results = await self.loader_func(batch_keys)            if isinstance(batch_results, dict):                results.update(batch_results)            elif isinstance(batch_results, list):                # Assume results are in same order as keys                for key, result in zip(batch_keys, batch_results):                    results[key] = result        return results    def _get_batch_key(self) -> str:        """Generate a batch key for grouping requests."""        # Using current time for simplicity, in a real system, consider a more robust batching mechanism        return f"batch_{int(asyncio.get_event_loop().time() * 1000)}"    async def _execute_batch(self, batch_key: str):        """Execute a batch of requests."""        if batch_key not in self._pending:            return        keys = self._pending[batch_key]        del self._pending[batch_key]        if not keys:            return        try:            # Execute batch loader            batch_results = await self.loader_func(keys)            # Store results            if isinstance(batch_results, dict):                self._results.update(batch_results)            elif isinstance(batch_results, list):                for key, result in zip(keys, batch_results):                    self._results[key] = result        except Exception as e:            logger.error(f"Batch loading failed: {e}")            # Set None for all keys on failure            for key in keys:                self._results[key] = Nonedef create_child_data_loader(loader_func: Callable) -> BatchLoader:    """Create a batch loader specifically for child data."""    return BatchLoader(loader_func, batch_size=10)  # Smaller batches for child data